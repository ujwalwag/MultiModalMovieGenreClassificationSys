{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42baf95b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# üì¶ Imports\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\__init__.py:2151\u001b[0m\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \u001b[38;5;66;03m# Import most common subpackages\u001b[39;00m\n\u001b[0;32m   2137\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \n\u001b[0;32m   2143\u001b[0m \u001b[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001b[39;00m\n\u001b[0;32m   2144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m   2145\u001b[0m     enable_grad \u001b[38;5;28;01mas\u001b[39;00m enable_grad,\n\u001b[0;32m   2146\u001b[0m     inference_mode \u001b[38;5;28;01mas\u001b[39;00m inference_mode,\n\u001b[0;32m   2147\u001b[0m     no_grad \u001b[38;5;28;01mas\u001b[39;00m no_grad,\n\u001b[0;32m   2148\u001b[0m     set_grad_enabled \u001b[38;5;28;01mas\u001b[39;00m set_grad_enabled,\n\u001b[0;32m   2149\u001b[0m )\n\u001b[1;32m-> 2151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2152\u001b[0m     __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__,\n\u001b[0;32m   2153\u001b[0m     __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__,\n\u001b[0;32m   2154\u001b[0m     _awaits \u001b[38;5;28;01mas\u001b[39;00m _awaits,\n\u001b[0;32m   2155\u001b[0m     accelerator \u001b[38;5;28;01mas\u001b[39;00m accelerator,\n\u001b[0;32m   2156\u001b[0m     autograd \u001b[38;5;28;01mas\u001b[39;00m autograd,\n\u001b[0;32m   2157\u001b[0m     backends \u001b[38;5;28;01mas\u001b[39;00m backends,\n\u001b[0;32m   2158\u001b[0m     cpu \u001b[38;5;28;01mas\u001b[39;00m cpu,\n\u001b[0;32m   2159\u001b[0m     cuda \u001b[38;5;28;01mas\u001b[39;00m cuda,\n\u001b[0;32m   2160\u001b[0m     distributed \u001b[38;5;28;01mas\u001b[39;00m distributed,\n\u001b[0;32m   2161\u001b[0m     distributions \u001b[38;5;28;01mas\u001b[39;00m distributions,\n\u001b[0;32m   2162\u001b[0m     fft \u001b[38;5;28;01mas\u001b[39;00m fft,\n\u001b[0;32m   2163\u001b[0m     futures \u001b[38;5;28;01mas\u001b[39;00m futures,\n\u001b[0;32m   2164\u001b[0m     hub \u001b[38;5;28;01mas\u001b[39;00m hub,\n\u001b[0;32m   2165\u001b[0m     jit \u001b[38;5;28;01mas\u001b[39;00m jit,\n\u001b[0;32m   2166\u001b[0m     linalg \u001b[38;5;28;01mas\u001b[39;00m linalg,\n\u001b[0;32m   2167\u001b[0m     mps \u001b[38;5;28;01mas\u001b[39;00m mps,\n\u001b[0;32m   2168\u001b[0m     mtia \u001b[38;5;28;01mas\u001b[39;00m mtia,\n\u001b[0;32m   2169\u001b[0m     multiprocessing \u001b[38;5;28;01mas\u001b[39;00m multiprocessing,\n\u001b[0;32m   2170\u001b[0m     nested \u001b[38;5;28;01mas\u001b[39;00m nested,\n\u001b[0;32m   2171\u001b[0m     nn \u001b[38;5;28;01mas\u001b[39;00m nn,\n\u001b[0;32m   2172\u001b[0m     optim \u001b[38;5;28;01mas\u001b[39;00m optim,\n\u001b[0;32m   2173\u001b[0m     overrides \u001b[38;5;28;01mas\u001b[39;00m overrides,\n\u001b[0;32m   2174\u001b[0m     profiler \u001b[38;5;28;01mas\u001b[39;00m profiler,\n\u001b[0;32m   2175\u001b[0m     sparse \u001b[38;5;28;01mas\u001b[39;00m sparse,\n\u001b[0;32m   2176\u001b[0m     special \u001b[38;5;28;01mas\u001b[39;00m special,\n\u001b[0;32m   2177\u001b[0m     testing \u001b[38;5;28;01mas\u001b[39;00m testing,\n\u001b[0;32m   2178\u001b[0m     types \u001b[38;5;28;01mas\u001b[39;00m types,\n\u001b[0;32m   2179\u001b[0m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[0;32m   2180\u001b[0m     xpu \u001b[38;5;28;01mas\u001b[39;00m xpu,\n\u001b[0;32m   2181\u001b[0m )\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m windows \u001b[38;5;28;01mas\u001b[39;00m windows\n\u001b[0;32m   2185\u001b[0m \u001b[38;5;66;03m# Quantized, sparse, AO, etc. should be last to get imported, as nothing\u001b[39;00m\n\u001b[0;32m   2186\u001b[0m \u001b[38;5;66;03m# is expected to depend on them.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\multiprocessing\\__init__.py:100\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of the current thread.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m        str: Name of the current thread.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_thread_name()\n\u001b[1;32m--> 100\u001b[0m \u001b[43minit_reductions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\multiprocessing\\reductions.py:629\u001b[0m, in \u001b[0;36minit_reductions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_reductions\u001b[39m():\n\u001b[1;32m--> 629\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mregister(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241m.\u001b[39mEvent, reduce_event)\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_storage_classes:\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUntypedStorage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "# üì¶ Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üîß Config\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "GENRE_COLUMNS = [\n",
    "    'Drama', 'Comedy', 'Romance', 'Thriller', 'Action',\n",
    "    'Horror', 'Documentary', 'Animation', 'Music', 'Crime'\n",
    "]\n",
    "\n",
    "# üì∂ Load artifacts\n",
    "embedding_matrix = np.load('models/embedding_matrix.npy')\n",
    "with open('models/tokenizer.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "model_state = torch.load('models/genre_classifier.pth', map_location=DEVICE)\n",
    "\n",
    "# üß† Define model\n",
    "class GenreLSTM(nn.Module):\n",
    "    def __init__(self, emb, hid=128, drop=0.3):\n",
    "        super().__init__()\n",
    "        vocab_size, emb_dim = emb.shape\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(emb, dtype=torch.float32), requires_grad=False)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.fc = nn.Linear(hid * 2, len(GENRE_COLUMNS))\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(self.embedding(x))\n",
    "        pooled = lstm_out.mean(dim=1)\n",
    "        dropped = self.dropout(pooled)\n",
    "        return self.fc(dropped)\n",
    "\n",
    "# üèóÔ∏è Instantiate model\n",
    "model = GenreLSTM(embedding_matrix).to(DEVICE)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "# üî† Tokenizer helper\n",
    "def texts_to_tensor(texts, max_len=200):\n",
    "    seqs = tokenizer.texts_to_sequences(texts)\n",
    "    arr = np.zeros((len(seqs), max_len), dtype=np.int64)\n",
    "    for i, seq in enumerate(seqs):\n",
    "        arr[i, :min(len(seq), max_len)] = seq[:max_len]\n",
    "    return torch.tensor(arr, dtype=torch.long)\n",
    "\n",
    "# üìÑ Load test data\n",
    "df = pd.read_csv('data/strictly_balanced_top10_cleaned.csv')  # expects \"overview\" and \"genres\" columns\n",
    "df.dropna(subset=['overview', 'genres'], inplace=True)\n",
    "\n",
    "# üéØ Encode true genres\n",
    "df['genres'] = df['genres'].apply(eval)  # from string to list if needed\n",
    "mlb = MultiLabelBinarizer(classes=GENRE_COLUMNS)\n",
    "y_true = mlb.fit_transform(df['genres'])\n",
    "\n",
    "# üßÆ Predictions\n",
    "batch_size = 64\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch_texts = df['overview'].iloc[i:i+batch_size].tolist()\n",
    "        tensor = texts_to_tensor(batch_texts).to(DEVICE)\n",
    "        logits = model(tensor)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        preds = (probs >= 0.5).astype(int)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "y_pred = np.vstack(all_preds)\n",
    "\n",
    "# üìä Report\n",
    "print(\"üìç Classification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=GENRE_COLUMNS, digits=3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
